# @package _global_
optimizer:
    name: sgd
    momentum: 0.9
    lr: 0.09 # learning rate
    weight_decay: 1e-4 # weight decay
    nesterov: false
    mini_batch_size: 512
